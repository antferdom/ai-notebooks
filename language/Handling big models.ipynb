{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db578e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72367e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556e4755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 25 15:33:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:03:00.0 Off |                  Off |\n",
      "| N/A   33C    P0    51W / 400W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfcdd",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4af439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/infra/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "088b8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env():\n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "    \n",
    "def set_seed(seed, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = deterministic\n",
    "        torch.backends.cudnn.benchmark = not deterministic\n",
    "        # torch.use_deterministic_algorithms(deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cf84785",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed: int = 42\n",
    "\n",
    "set_env()\n",
    "set_seed(rng_seed, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0baa3ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1332, 0.9346, 0.5936]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify deterministic pseudo-random number generator\n",
    "torch.rand(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fafba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sharded model weights\\nmodel_name = \"incoder-6B\"\\nmodel_id=f\"facebook/{model_name}\"\\n\\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/incoder-6B\", revision=\"sharded\", low_cpu_mem_usage=True)\\n#model = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True)\\ntokenizer = AutoTokenizer.from_pretrained(model_id)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Sharded model weights\n",
    "model_name = \"incoder-6B\"\n",
    "model_id=f\"facebook/{model_name}\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/incoder-6B\", revision=\"sharded\", low_cpu_mem_usage=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86a0a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'Optional',\n",
       " 'OutOfMemoryError',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_LazySeedTracker',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_count_nvml',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_get_device_index',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_compiled',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_memory_viz',\n",
       " '_parse_visible_devices',\n",
       " '_queued_calls',\n",
       " '_raw_device_count_nvml',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_utils',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'can_device_access_peer',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'contextlib',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_current_stream_capturing',\n",
       " 'is_initialized',\n",
       " 'jiterator',\n",
       " 'list_gpu_processes',\n",
       " 'lru_cache',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a75ff150",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-mono\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d4bd813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "074b7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 2560)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=2560, out_features=7680, bias=False)\n",
       "          (out_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc_out): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-2B-mono\", torch_dtype=torch.bfloat16).cuda()\n",
    "model.bfloat16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "194c4775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.692930048"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model memory footprint (GB)\n",
    "model.get_memory_footprint() / 10**9\n",
    "# Flush GPU memory and delete the model\n",
    "#Â del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e087a2f",
   "metadata": {},
   "source": [
    "# CodeGen Tokenizer caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tokenizer for CodeGen\n",
    "\"\"\"\n",
    "Construct a CodeGen tokenizer. Based on byte-level Byte-Pair-Encoding.\n",
    "This tokenizer has been trained to treat spaces like parts of the tokens (a bit like sentencepiece) so a word will\n",
    "be encoded differently whether it is at the beginning of the sentence (without space) or not:\n",
    "\n",
    ">>> tokenizer(\"Hello world\")['input_ids']\n",
    "[15496, 995]\n",
    ">>> tokenizer(\" Hello world\")['input_ids']\n",
    "[18435, 995]\n",
    "\"\"\"\n",
    "def include_whitespace(t, n_min=2, n_max=20, as_special_tokens=False):\n",
    "    t.add_tokens([' ' * n for n in reversed(range(n_min, n_max))], special_tokens=as_special_tokens)\n",
    "    return t\n",
    "\n",
    "\n",
    "def include_tabs(t, n_min=2, n_max=20, as_special_tokens=False):\n",
    "    t.add_tokens(['\\t' * n for n in reversed(range(n_min, n_max))], special_tokens=as_special_tokens)\n",
    "    return t\n",
    "\n",
    "\n",
    "def create_custom_gpt2_tokenizer():\n",
    "    t = tokenizer\n",
    "    t = include_whitespace(t=t, n_min=2, n_max=32, as_special_tokens=False)\n",
    "    t = include_tabs(t=t, n_min=2, n_max=10, as_special_tokens=False)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd7519",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bc826",
   "metadata": {},
   "source": [
    "## Sampling with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c07f4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 6738, 19720,  1330,  7343,    11,   309, 29291,   198,  4299, 10708,\n",
      "            62,  9806,     7,    77, 17024,    25,  7343,    58,   600, 12962,\n",
      "          4613,  7343,    58,   600,  5974,   198, 50284, 37811,  3574,   257,\n",
      "          1813,  1351,   286, 37014,    11,  7716,   257,  1351,   286, 10708,\n",
      "          5415,  5002,  1043,  1566,  1813,  2589,   198, 50284,   259,   262,\n",
      "          8379,    13, 37227,   198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "('self', 'token_ids', 'skip_special_tokens', 'clean_up_tokenization_spaces', 'truncate_before_pattern', 'kwargs', 'decoded_text')\n",
      "HumanEval Problem Statement\n",
      "from typing import List, Tuple\n",
      "def rolling_max(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a given list of integers, generate a list of rolling maximum element found until given moment\n",
      "    in the sequence. \"\"\"\n",
      "\n",
      "HumanEval Problem Solution\n",
      "from typing import List, Tuple\n",
      "def rolling_max(numbers: List[int]) -> List[int]:\n",
      "    \"\"\" From a given list of integers, generate a list of rolling maximum element found until given moment\n",
      "    in the sequence. \"\"\"\n",
      "    max_list = []\n",
      "    for i in range(len(numbers)):\n",
      "        max_list.append(max(numbers[i:i+2]))\n",
      "    return max_list\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Tokenizers Fast -> Rust implementation performance boost\n",
    "context: str = \"from typing import List, Tuple\\ndef rolling_max(numbers: List[int]) -> List[int]:\\n    \\\"\\\"\\\" From a given list of integers, generate a list of rolling maximum element found until given moment\\n    in the sequence. \\\"\\\"\\\"\\n\"\n",
    "inputs = tokenizer(context, return_tensors=\"pt\").to(0)\n",
    "print(inputs)\n",
    "pad_token_id: int = 50256\n",
    "sample = model.generate(**inputs, max_length=128)\n",
    "\"\"\"\n",
    "CodeGenTokenizer\n",
    "\n",
    "args:\n",
    "    token_ids\n",
    "    skip_special_tokens\n",
    "    clean_up_tokenization_spaces\n",
    "    truncate_before_pattern\n",
    "\"\"\"\n",
    "print(tokenizer.decode.__code__.co_varnames)\n",
    "print(\"HumanEval Problem Statement\")\n",
    "print(context)\n",
    "print(\"HumanEval Problem Solution\")\n",
    "print(tokenizer.decode(sample[0], truncate_before_pattern=[r\"\\n\\n^#\", \"^'''\", \"\\n\\n\\n\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710536f0",
   "metadata": {},
   "source": [
    "## Manual Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63909ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def truncate(completion):\n",
    "\n",
    "    def find_re(string, pattern, start_pos):\n",
    "        m = pattern.search(string, start_pos)\n",
    "        return m.start() if m else -1\n",
    "\n",
    "    terminals = [\n",
    "        re.compile(r, re.MULTILINE)\n",
    "        for r in\n",
    "        [\n",
    "            '^#',\n",
    "            re.escape('<|endoftext|>'),\n",
    "            \"^'''\",\n",
    "            '^\"\"\"',\n",
    "            '\\n\\n\\n'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    prints = list(re.finditer('^print', completion, re.MULTILINE))\n",
    "    if len(prints) > 1:\n",
    "        completion = completion[:prints[1].start()]\n",
    "\n",
    "    defs = list(re.finditer('^def', completion, re.MULTILINE))\n",
    "    if len(defs) > 1:\n",
    "        completion = completion[:defs[1].start()]\n",
    "\n",
    "    start_pos = 0\n",
    "\n",
    "    terminals_pos = [pos for pos in [find_re(completion, terminal, start_pos) for terminal in terminals] if pos != -1]\n",
    "    if len(terminals_pos) > 0:\n",
    "        return completion[:min(terminals_pos)]\n",
    "    else:\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(\n",
    "    device,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    context: str,\n",
    "    pad_token_id: int,\n",
    "    num_return_sequences: int,\n",
    "    temp: float,\n",
    "    top_p: float,\n",
    "    max_length_sample: int,\n",
    "    max_length: int\n",
    "):\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        context,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "    ).input_ids\n",
    "\n",
    "    input_ids_len = input_ids.shape[1]\n",
    "    assert input_ids_len < max_length\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        tokens = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            temperature=temp,\n",
    "            max_length=input_ids_len + max_length_sample,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=pad_token_id,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        text = tokenizer.batch_decode(tokens[:, input_ids_len:, ...])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a4672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cuda:0\"\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d65444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) params\n",
    "device: str = \"cuda:0\"\n",
    "rng_seed: int = 42\n",
    "top_p: float = 0.95\n",
    "temp: float = 0.01\n",
    "max_length_sample: int = 128\n",
    "batch_size: int = 1\n",
    "pad_token_id: int = 50256\n",
    "context: str = \"def helloworld():\"\n",
    "\n",
    "# (2) preamble\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fcb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.manual_seed(42)\n",
    "torch.rand(1,3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afda621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion\n",
      "====================================================================================================\n",
      "\n",
      "    print(\"Hello World\")\n",
      "\n",
      "helloworld()\n",
      "\n",
      "def hello(name):\n",
      "    print(\"Hello\", name)\n",
      "\n",
      "hello(\"John\")\n",
      "\n",
      "def hello(name, age):\n",
      "    print(\"Hello\", name, \"you are\", age)\n",
      "\n",
      "hello(\"John\", 25)\n",
      "\n",
      "def hello(name, age):\n",
      "    print(\"Hello\", name, \"you are\", age)\n",
      "\n",
      "hello(\"John\", 25)\n",
      "\n",
      "def hello(name, age):\n",
      "    print(\"Hello\", name, \"you are\", age)\n",
      "\n",
      "hello(\"John\", 25)\n",
      "\n",
      "Context + Truncation\n",
      "====================================================================================================\n",
      "def helloworld():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "helloworld()\n",
      "\n",
      "def hello(name):\n",
      "    print(\"Hello\", name)\n",
      "\n",
      "hello(\"John\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3) tokenizer\n",
    "# For models fine-tuned on code\n",
    "tokenizer = create_custom_gpt2_tokenizer()\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = pad_token_id\n",
    "# (4) sample\n",
    "completion = sample(device=device, model=model, tokenizer=tokenizer, context=context\n",
    "                    , pad_token_id=pad_token_id, num_return_sequences=batch_size, temp=temp\n",
    "                    , top_p=top_p, max_length_sample=max_length_sample,  max_length=2048)[0]\n",
    "truncation = truncate(completion)\n",
    "\n",
    "print(\"Completion\")\n",
    "print('=' * 100)\n",
    "print(completion)\n",
    "print(\"Context + Truncation\")\n",
    "print('=' * 100)\n",
    "print(context + truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52510296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    print(\"Hello World\")\n",
      "\n",
      "helloworld()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "curated_completion: str = \"\"\n",
    "    \n",
    "for line in completion.split(\"\\n\"):\n",
    "    if \"def\" in line and \"def helloworld():\" not in line:\n",
    "        break\n",
    "    else:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6689f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "        255, 255,  42,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,\n",
       "          0,   0,   0,   0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_rng_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c82218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('infra': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "ad9f76696a71bb27aca0bfcf6d796b777445273d0fdb2534594cb67215773d8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
